for(i in 1:1000){
cmr <- capt_marq_recapt(j, 0.15)
while(cmr[[3]] == 0){
cmr <- capt_marq_recapt(j, 0.15)
}
estimation <- cmr[[1]]*(cmr[[2]]+cmr[[3]])/cmr[[3]]
hat_Ns <- c(hat_Ns, estimation)
}
biais <- c(biais, mean(hat_Ns) - j)
}
plot(N, biais, ylab = 'biais relatif', xlab = 'Ntrue')
reg <- lm(biais ~ N)
plot(N, fitted(reg), type = 'l',xlab = 'Ntrue', ylab = 'y', main = 'regression linéaire du biais relatif')
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
19*(13+2)/2
N
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
capt_marq_recapt(100, 0.15)
21*(13+4)/4
N <- seq(100, 1000, 10)
biais <- c()
for(j in N){
hat_Ns <- c()
for(i in 1:100){
cmr <- capt_marq_recapt(j, 0.15)
while(cmr[[3]] == 0){
cmr <- capt_marq_recapt(j, 0.15)
}
estimation <- cmr[[1]]*(cmr[[2]]+cmr[[3]])/cmr[[3]]
hat_Ns <- c(hat_Ns, estimation)
}
biais <- c(biais, mean(hat_Ns) - j)
}
plot(N, biais, ylab = 'biais relatif', xlab = 'Ntrue')
reg <- lm(biais ~ N)
plot(N, fitted(reg), type = 'l',xlab = 'Ntrue', ylab = 'y', main = 'regression linéaire du biais relatif')
N <- seq(100, 1000, 10)
biais <- c()
for(j in N){
hat_Ns <- c()
for(i in 1:100){
cmr <- capt_marq_recapt(j, 0.15)
while(cmr[[3]] == 0){
cmr <- capt_marq_recapt(j, 0.15)
}
estimation <- cmr[[1]]*(cmr[[2]]+cmr[[3]])/cmr[[3]]
hat_Ns <- c(hat_Ns, estimation)
}
biais <- c(biais, mean(hat_Ns) - j)
}
plot(N, biais, ylab = 'biais relatif', xlab = 'Ntrue')
reg <- lm(biais ~ N)
plot(N, fitted(reg), type = 'l',xlab = 'Ntrue', ylab = 'y', main = 'regression linéaire du biais relatif')
N <- seq(100, 1000, 10)
biais <- c()
for(j in N){
hat_Ns <- c()
for(i in 1:100){
cmr <- capt_marq_recapt(j, 0.15)
while(cmr[[3]] == 0){
cmr <- capt_marq_recapt(j, 0.15)
}
estimation <- cmr[[1]]*(cmr[[2]]+cmr[[3]])/cmr[[3]]
hat_Ns <- c(hat_Ns, estimation)
}
biais <- c(biais, mean(hat_Ns) - j)
}
plot(N, biais, ylab = 'biais relatif', xlab = 'Ntrue')
reg <- lm(biais ~ N)
plot(N, fitted(reg), type = 'l',xlab = 'Ntrue', ylab = 'y', main = 'regression linéaire du biais relatif')
N <- seq(100, 10000, 10)
biais <- c()
for(j in N){
hat_Ns <- c()
for(i in 1:100){
cmr <- capt_marq_recapt(j, 0.15)
while(cmr[[3]] == 0){
cmr <- capt_marq_recapt(j, 0.15)
}
estimation <- cmr[[1]]*(cmr[[2]]+cmr[[3]])/cmr[[3]]
hat_Ns <- c(hat_Ns, estimation)
}
biais <- c(biais, mean(hat_Ns) - j)
}
plot(N, biais, ylab = 'biais relatif', xlab = 'Ntrue')
reg <- lm(biais ~ N)
plot(N, fitted(reg), type = 'l',xlab = 'Ntrue', ylab = 'y', main = 'regression linéaire du biais relatif')
N <- seq(100, 1000, 10)
biais <- c()
for(j in N){
hat_Ns <- c()
for(i in 1:100){
cmr <- capt_marq_recapt(j, 0.15)
while(cmr[[3]] == 0){
cmr <- capt_marq_recapt(j, 0.15)
}
estimation <- cmr[[1]]*(cmr[[2]]+cmr[[3]])/cmr[[3]]
hat_Ns <- c(hat_Ns, estimation)
}
biais <- c(biais, (mean(hat_Ns) - j)/j)
}
plot(N, biais, ylab = 'biais relatif', xlab = 'Ntrue')
N <- seq(100, 1000, 10)
biais <- c()
for(j in N){
hat_Ns <- c()
for(i in 1:100){
cmr <- capt_marq_recapt(j, 0.15)
while(cmr[[3]] == 0){
cmr <- capt_marq_recapt(j, 0.15)
}
estimation <- cmr[[1]]*(cmr[[2]]+cmr[[3]])/cmr[[3]]
hat_Ns <- c(hat_Ns, estimation)
}
biais <- c(biais, (mean(hat_Ns) - j)/j)
}
plot(N, biais, ylab = 'biais relatif', xlab = 'Ntrue')
N <- seq(100, 10000, 10)
biais <- c()
for(j in N){
hat_Ns <- c()
for(i in 1:100){
cmr <- capt_marq_recapt(j, 0.15)
while(cmr[[3]] == 0){
cmr <- capt_marq_recapt(j, 0.15)
}
estimation <- cmr[[1]]*(cmr[[2]]+cmr[[3]])/cmr[[3]]
hat_Ns <- c(hat_Ns, estimation)
}
biais <- c(biais, (mean(hat_Ns) - j)/j)
}
plot(N, biais, ylab = 'biais relatif', xlab = 'Ntrue')
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # Ensemble de packages pour la manip de donnes
library(latex2exp) # permet d'ajouter des equations latex aux figures
library(numDeriv) # calculer des dérivées par différences finies
rm(list=ls()) # Nettoyage de l'environnement de travail
?dbeta
dbeta(0.5, 120, 80)
x <- seq(0, 1, length.out = 100)
plot(x, dbeta(x, 1, 3))
plot(x, dbeta(x, 1, 3), type = 'l')
lines(x, dbeta(x, 281, 1623), type = 'l')
x <- seq(0, 1, length.out = 100)
plot(x, dbeta(x, 1, 3), type = 'l')
lines(x, dbeta(x, 281, 1623), type = 'l')
abline(v = (125+134+21)/(2*950))
x <- seq(0, 1, length.out = 1000)
plot(x, dbeta(x, 1, 3), type = 'l')
x <- seq(0, 1, length.out = 1000)
plot(x, dbeta(x, 1, 3), type = 'l')
lines(x, dbeta(x, 281, 1623), type = 'l')
abline(v = (125+134+21)/(2*950))
x <- seq(0, 1, length.out = 1000)
plot(x, dbeta(x, 1, 3), type = 'l', col = 'red')
lines(x, dbeta(x, 281, 1623), type = 'l', col = 'blue')
abline(v = (125+134+21)/(2*950), col = 'black')
setwd("~/Documents/ENSTA_2021/STA211/Projet")
library(tidyverse) # Ensemble de packages pour la manip de donnes
library(latex2exp)
rm(list=ls()) # Nettoyage de l'environnement de travail
set.seed(123) # Assure la reproductibilite des resultats
x <- seq(0, 1, length.out = 1000)
plot(x, dbeta(x, 1, 3), type = 'l', col = 'red')
lines(x, dbeta(x, 281, 1623), type = 'l', col = 'blue')
abline(v = (125+134+21)/(2*950), col = 'black')
legend("topright", legend=c("a priori", "a posteriori", TeX("$\hat{\pi}_{MLE}$")), bty='n', pch=rep('_',3), col=c(4,2,1))
x <- seq(0, 1, length.out = 1000)
plot(x, dbeta(x, 1, 3), type = 'l', col = 'red')
lines(x, dbeta(x, 281, 1623), type = 'l', col = 'blue')
abline(v = (125+134+21)/(2*950), col = 'black')
legend("topright", legend=c("a priori", "a posteriori", TeX("$\\hat{\\pi}_{MLE}$")), bty='n', pch=rep('_',3), col=c(4,2,1))
x <- seq(0, 1, length.out = 1000)
plot(x, dbeta(x, 1, 3), type = 'l', col = 'red')
lines(x, dbeta(x, 281, 1623), type = 'l', col = 'blue')
abline(v = (125+134+21)/(2*950), col = 'black')
legend("topright", legend=c("a priori", "a posteriori", TeX("$\\hat{\\pi}_{MLE}$")), bty='n', pch=rep('_',3), col=c(2,4,1))
x <- seq(0, 1, length.out = 1000)
plot(x, dbeta(x, 1, 3), type = 'l', col = 'red')
lines(x, dbeta(x, 281, 1623), type = 'l', col = 'blue')
abline(v = (125+134+21)/(2*950), col = 'black')
legend("topright", legend=c("a priori", "a posteriori", TeX("$\\hat{\\pi}_{MLE}$")), bty='n', pch=rep('_',3), col=c(7,4,1))
x <- seq(0, 1, length.out = 1000)
plot(x, dbeta(x, 1, 3), type = 'l', col = 'red')
lines(x, dbeta(x, 281, 1623), type = 'l', col = 'blue')
abline(v = (125+134+21)/(2*950), col = 'black')
legend("topright", legend=c("a priori", "a posteriori", TeX("$\\hat{\\pi}_{MLE}$")), bty='n', pch=rep('_',3), col=c(2,4,1))
x <- seq(0, 1, length.out = 1000)
plot(x, dbeta(x, 1, 3), type = 'l', col = 2)
lines(x, dbeta(x, 281, 1623), type = 'l', col = 'blue')
abline(v = (125+134+21)/(2*950), col = 'black')
legend("topright", legend=c("a priori", "a posteriori", TeX("$\\hat{\\pi}_{MLE}$")), bty='n', pch=rep('_',3), col=c(2,4,1))
x <- seq(0, 1, length.out = 1000)
plot(x, dbeta(x, 1, 3), type = 'l', col = 2)
lines(x, dbeta(x, 281, 1623), type = 'l', col = 4)
abline(v = (125+134+21)/(2*950), col = 1)
legend("topright", legend=c("a priori", "a posteriori", TeX("$\\hat{\\pi}_{MLE}$")), bty='n', pch=rep('_',3), col=c(2,4,1))
install.packages('devtools')
devtools::install_url("http://sourceforge.net/projects/mcmc-jags/files/rjags/3/rjags_3-2.tar.gz",
args="--configure-args='--with-jags-include=/Users/casallas/homebrew/opt/jags/include/JAGS
--with-jags-lib=/Users/casallas/homebrew/opt/jags/lib'
"
)
devtools::install_url("http://sourceforge.net/projects/mcmc-jags/files/rjags/3/rjags_3-2.tar.gz", args="--configure-args='--with-jags-include=/Users/casallas/homebrew/opt/jags/include/JAGS
--with-jags-lib=/Users/casallas/homebrew/opt/jags/lib'")
n
N
devtools::install_url("http://sourceforge.net/projects/mcmc-jags/files/rjags/3/rjags_3-2.tar.gz", args="--configure-args='--with-jags-include=/usr/local/homebrew/opt/jags/include/JAGS
--with-jags-lib=/usr/local/homebrew/opt/jags/lib'")
knitr::opts_chunk$set(echo = TRUE)
library(cxoda)
require(coda)
library(rjags)
library(ggmcmc)
library(mvtnorm)
library(tidyverse) # Ensemble de packages pour la manip des donnees
library(latex2exp) # permet d'ajouter des equations latex aux figures
install.packages('rjags')
library(rjags, lib.loc = '/var/folders/4k/w9dj1p_52h917f289h083y7m0000gn/T//RtmpyxudRI/downloaded_packages')
library(rjags, lib.loc = '/var/folders/4k/w9dj1p_52h917f289h083y7m0000gn/T//RtmpyxudRI/downloaded_packages/rjags')
library(rjags, lib.loc = '/var/folders/4k/w9dj1p_52h917f289h083y7m0000gn/T//RtmpyxudRI/downloaded_packages/')
knitr::opts_chunk$set(echo = TRUE)
alpha <- 1
beta <- 3
MCMC <- function(c1, c20, c21, k, T, N = 800, p = 0.5){
# Condition initiale
taux <- 0
# Boucle sur les itérations
for(i in 1:(T-1)){
# Metropolis-Hastings
Ninter <- N[i]
Ncandidat <- (runif(1, max(Ninter-k, max(c1, c20 + c21)), Ninter+k+1)) # simulation sous une unif(N-k, N+k) discrète
r <- (1-p)^(2*abs(Ncandidat-Ninter)) # calcul du ratio de MH
U <- runif(1)
if(U < min(1, r)){
N <- c(N, Ncandidat)
taux <- taux +1
}
else{
N <- c(N, Ninter)
}
# Gibbs
p <- c(p, rbeta(1, c1 + c20 + c21 + alpha, 2*N[i+1]-c1-c21-c20+beta))
}
# return(list(N = N, pi = p, taux = taux/T))
return(list(mcmc = mcmc(matrix(c(p,N),nrow=T,ncol=2,byrow=FALSE)), taux = taux /T))
}
test=MCMC(c1, c20, c21, 2, 10000, 1000, 0.15)
my_rbinom <- function(n ,m, pi ){
p <- pbinom(0:m, m, pi)
U <- runif(n)
return( findInterval( U, p ) )
}
n <- 1000000
m <- 125
pi <- 0.15
ech <- my_rbinom(n, m, pi)
paste('Esperance empirique : ', mean(ech))
paste('Esperance théorique :' ,125*0.15)
hist(ech, breaks = 30, xlim = c(5,35))
lines(x = 5:35, y = (n*dbinom(0:m, m, pi))[6:36] ) #Décalage de 1 dans les indices
capt_marq_recapt <- function(N, pi){
C1 = my_rbinom(1, N, pi)
C20 = my_rbinom(1, N-C1, pi)
C21 = my_rbinom(1, C1, pi)
return(list(C1, C20, C21))
}
paste('Estimation du paramètre', (125+134+21)/(2*950))
x <- seq(0, 1, length.out = 1000)
plot(x, dbeta(x, 1, 3), type = 'l', col = 2)
lines(x, dbeta(x, 281, 1623), type = 'l', col = 4)
abline(v = (125+134+21)/(2*950), col = 1)
legend("topright", legend=c("a priori", "a posteriori", TeX("$\\hat{\\pi}_{MLE}$")), bty='n', pch=rep('_',3), col=c(2,4,1))
paste('Estimation de N:', 125*(134+21)/21)
N <- seq(100, 1000, 10)
biais <- c()
for(j in N){
hat_Ns <- c()
for(i in 1:100){
cmr <- capt_marq_recapt(j, 0.15)
while(cmr[[3]] == 0){
cmr <- capt_marq_recapt(j, 0.15)
}
estimation <- cmr[[1]]*(cmr[[2]]+cmr[[3]])/cmr[[3]]
hat_Ns <- c(hat_Ns, estimation)
}
biais <- c(biais, (mean(hat_Ns) - j)/j)
}
plot(N, biais, ylab = 'biais relatif', xlab = 'Ntrue')
alpha <- 1
beta <- 3
MCMC <- function(c1, c20, c21, k, T, N = 800, p = 0.5){
# Condition initiale
taux <- 0
# Boucle sur les itérations
for(i in 1:(T-1)){
# Metropolis-Hastings
Ninter <- N[i]
Ncandidat <- (runif(1, max(Ninter-k, max(c1, c20 + c21)), Ninter+k+1)) # simulation sous une unif(N-k, N+k) discrète
r <- (1-p)^(2*abs(Ncandidat-Ninter)) # calcul du ratio de MH
U <- runif(1)
if(U < min(1, r)){
N <- c(N, Ncandidat)
taux <- taux +1
}
else{
N <- c(N, Ninter)
}
# Gibbs
p <- c(p, rbeta(1, c1 + c20 + c21 + alpha, 2*N[i+1]-c1-c21-c20+beta))
}
# return(list(N = N, pi = p, taux = taux/T))
return(list(mcmc = mcmc(matrix(c(p,N),nrow=T,ncol=2,byrow=FALSE)), taux = taux /T))
}
test=MCMC(c1, c20, c21, 2, 10000, 1000, 0.15)
alpha <- 1
beta <- 3
MCMC <- function(c1, c20, c21, k, T, N = 800, p = 0.5){
# Condition initiale
taux <- 0
# Boucle sur les itérations
for(i in 1:(T-1)){
# Metropolis-Hastings
Ninter <- N[i]
Ncandidat <- (runif(1, max(Ninter-k, max(c1, c20 + c21)), Ninter+k+1)) # simulation sous une unif(N-k, N+k) discrète
r <- (1-p)^(2*abs(Ncandidat-Ninter)) # calcul du ratio de MH
U <- runif(1)
if(U < min(1, r)){
N <- c(N, Ncandidat)
taux <- taux +1
}
else{
N <- c(N, Ninter)
}
# Gibbs
p <- c(p, rbeta(1, c1 + c20 + c21 + alpha, 2*N[i+1]-c1-c21-c20+beta))
}
# return(list(N = N, pi = p, taux = taux/T))
return(list(mcmc = mcmc(matrix(c(p,N),nrow=T,ncol=2,byrow=FALSE)), taux = taux /T))
}
test=MCMC(125, 134, 21, 2, 10000, 1000, 0.15)
test$mcmc
plot(test$mcmc)
alpha <- 1
beta <- 3
MCMC <- function(c1, c20, c21, k, T, N = 800, p = 0.5){
# Condition initiale
taux <- 0
# Boucle sur les itérations
for(i in 1:(T-1)){
# Metropolis-Hastings
Ninter <- N[i]
Ncandidat <- (runif(1, max(Ninter-k, max(c1, c20 + c21)), Ninter+k+1)) # simulation sous une unif(N-k, N+k) discrète
r <- (1-p)^(2*(Ncandidat-Ninter)) # calcul du ratio de MH
U <- runif(1)
if(U < min(1, r)){
N <- c(N, Ncandidat)
taux <- taux +1
}
else{
N <- c(N, Ninter)
}
# Gibbs
p <- c(p, rbeta(1, c1 + c20 + c21 + alpha, 2*N[i+1]-c1-c21-c20+beta))
}
# return(list(N = N, pi = p, taux = taux/T))
return(list(mcmc = mcmc(matrix(c(p,N),nrow=T,ncol=2,byrow=FALSE)), taux = taux /T))
}
test=MCMC(125, 134, 21, 2, 10000, 1000, 0.15)
test$mcmc
plot(test$mcmc)
alpha <- 1
beta <- 3
MCMC <- function(c1, c20, c21, k, T, N = 800, p = 0.5){
# Condition initiale
taux <- 0
# Boucle sur les itérations
for(i in 1:(T-1)){
# Metropolis-Hastings
Ninter <- N[i]
Ncandidat <- (runif(1, max(Ninter-k, max(c1, c20 + c21)), Ninter+k+1)) # simulation sous une unif(N-k, N+k) discrète
r <- (1-p)^(2*(Ncandidat-Ninter)) # calcul du ratio de MH
U <- runif(1)
if(U < min(1, r)){
N <- c(N, Ncandidat)
taux <- taux +1
}
else{
N <- c(N, Ninter)
}
# Gibbs
p <- c(p, rbeta(1, c1 + c20 + c21 + alpha, 2*N[i+1]-c1-c21-c20+beta))
}
# return(list(N = N, pi = p, taux = taux/T))
return(list(mcmc = mcmc(matrix(c(p,N),nrow=T,ncol=2,byrow=FALSE)), taux = taux /T))
}
test=MCMC(125, 134, 21, 2, 10000, 1000, 0.15)
test$mcmc
plot(test$mcmc)
K <- seq(1, 301,10)
c1 <- 125
c20 <- 134
c21 <- 21
taux <- c()
for(k in K){
paste('cool')
res <- MCMC(c1, c20, c21, k, 10000)
taux <- c(taux, res['taux'])
}
plot(K, taux, xlab = 'Paramètre k', ylab = 'taux d\'acceptation')
K <- seq(1, 10)
c1 <- 125
c20 <- 134
c21 <- 21
taux <- c()
for(k in K){
paste('cool')
res <- MCMC(c1, c20, c21, k, 10000)
taux <- c(taux, res['taux'])
}
K <- seq(1, 10)
c1 <- 125
c20 <- 134
c21 <- 21
taux <- c()
for(k in K){
paste('cool')
res <- MCMC(c1, c20, c21, k, 10000)
taux <- c(taux, res['taux'])
}
plot(K, taux, xlab = 'Paramètre k', ylab = 'taux d\'acceptation')
N0 <- 800
N1 <- 400
N2 <- 1200
p0 <- 0.5
p1 <- 0.5
p2 <- 0.5
res0 <- MCMC(c1, c20, c21, 2, 20000, N0, p0)
res1 <- MCMC(c1, c20, c21, 2, 20000, N1, p1)
res2 <- MCMC(c1, c20, c21, 2, 20000, N2, p2)
plot(unlist(res0['N']), unlist(res0['pi']))
N0 <- 800
N1 <- 400
N2 <- 1200
p0 <- 0.5
p1 <- 0.5
p2 <- 0.5
res0 <- MCMC(c1, c20, c21, 2, 20000, N0, p0)
res1 <- MCMC(c1, c20, c21, 2, 20000, N1, p1)
res2 <- MCMC(c1, c20, c21, 2, 20000, N2, p2)
plot(res0$mcmc)
plot(res1$mcmc)
plot(res2$mcmc)
N0 <- 800
N1 <- 400
N2 <- 1200
p0 <- 0.5
p1 <- 0.5
p2 <- 0.15
res0 <- MCMC(125, 134, 21, 2, 20000, N0, p0)
res1 <- MCMC(125, 134, 21, 2, 20000, N1, p1)
res2 <- MCMC(125, 134, 21, 2, 20000, N2, p2)
plot(res0$mcmc)
plot(res1$mcmc)
plot(res2$mcmc)
N0 <- 800
N1 <- 900
N2 <- 1200
p0 <- 0.5
p1 <- 0.2
p2 <- 0.15
res0 <- MCMC(125, 134, 21, 2, 20000, N0, p0)
res1 <- MCMC(125, 134, 21, 2, 20000, N1, p1)
res2 <- MCMC(125, 134, 21, 2, 20000, N2, p2)
plot(res0$mcmc)
plot(res1$mcmc)
plot(res2$mcmc)
